{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Burrow Fear Conditioning Analysis Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is a jupyter notebook to conduct the 'standard' analysis of burrow fear conditioning data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Experiment Hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we construct and organizational framework for the various behavioral stages and meta-data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from AnalysisModules.ExperimentHierarchy import ExperimentData\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identify Directory, Study, & Mouse Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "__directory=\"H:\\\\DEM_Excitatory_Study\\\\DEM2\"\n",
    "__mouse=\"M4584\"\n",
    "__study=\"DEM\"\n",
    "__study_mouse=\"DEM2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Construct Experiment Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Data = ExperimentData(Directory=__directory, Mouse=__mouse, Study=__study, StudyMouse=__study_mouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conduct Analysis on Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from AnalysisModules.BurrowFearConditioning import Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Data.Encoding = Encoding(Data.passMeta())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identify Dataset and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "__data_folder = \"H:\\\\DEM_Excitatory_Study\\\\DEM2\\\\Encoding\\\\Imaging\\\\10Hz\"\n",
    "__index_file = \"H:\\\\DEM_Excitatory_Study\\\\DEM2\\\\Encoding\\\\Imaging\\\\10Hz\\\\NeuronalIndex.csv\"\n",
    "__features_file = \"H:\\\\DEM_Excitatory_Study\\\\DEM2\\\\Encoding\\\\Imaging\\\\10Hz\\\\Features.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\Calcium-Imaging-Analysis-Pipeline\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tYAML reader installed (version 0.17.17).\n",
      "\tKeras installed (version 2.3.1).\n",
      "\tTensorflow installed (version 2.3.0).\n"
     ]
    }
   ],
   "source": [
    "# FISSA: Signal Extraction & Source-Separation\n",
    "from AnalysisModules.FissaAnalysis import FissaModule\n",
    "\n",
    "# CASCADE: Spike Inference\n",
    "from AnalysisModules.CascadeAnalysis import CascadeModule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Instantiation / Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting from 1-to-0 indexing\n",
      "Initialized Fissa\n",
      "Loading Fissa Preparation...\n",
      "Finished Loading Fissa Prep\n",
      "Loading Fissa Separation...\n",
      "Finished Loading Fissa Sep\n",
      "Loading Processed Traces...\n",
      "Finished Loading Processed Traces.\n",
      "Loading Spike Probabilities from Load Path...\n",
      "Finished Loading Spike Probabilities\n",
      "Loading Spike Times from Load Path...\n",
      "Loading Discrete Approximations from Load Path...\n",
      "Loading Processed Inferences...\n",
      "Finished Loading Processed Traces.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Fissa Module & Sub-Modules. \n",
    "# Sub-Module 1 is preparation, will contain raw data (PreparationModule)\n",
    "# Sub-Module 2 is experiment, will contain separation data (SeparationModule)\n",
    "# Sub-Module 3 is ProcessedTraces, just a container for processed signals\n",
    "Data.Encoding.Fissa = FissaModule(data_folder=__data_folder, index_file = __index_file)\n",
    "# This folder contains the suite2p/plane0/___.npy files as well as the saved registered files located in the suite2p/plane0/reg_tif folder\n",
    "# Initialize\n",
    "Data.Encoding.Fissa.pruneNonNeuronalROIs() # This step removes all non-neuronal data\n",
    "Data.Encoding.Fissa.initializeFissa()\n",
    "Data.Encoding.Fissa.loadFissaPrep()\n",
    "Data.Encoding.Fissa.loadFissaSep()\n",
    "Data.Encoding.Fissa.loadProcessedTraces()\n",
    "# Cascade\n",
    "Data.Encoding.Cascade = CascadeModule(Data.Encoding.Fissa.ProcessedTraces.detrended_merged_dFoF_result, Data.Encoding.Fissa.frame_rate, model_folder=\"C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\suite2p\\\\Pretrained_models\")\n",
    "Data.Encoding.Cascade.loadSpikeProb(load_path=Data.Encoding.Fissa.output_folder)\n",
    "Data.Encoding.Cascade.loadSpikeInference(load_path=Data.Encoding.Fissa.output_folder)\n",
    "Data.Encoding.Cascade.loadProcessedInferences(load_path=Data.Encoding.Fissa.output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Data.saveHierarchy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Event-Based Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from AnalysisModules.StaticProcessing import generateSpikeMatrix\n",
    "from AnalysisModules.DecodingAnalysis import LogisticRegression\n",
    "from AnalysisModules.BurrowFearConditioning import identifyTrialValence, reorganizeData"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate Spike Matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Yet Implemented\n"
     ]
    },
    {
     "data": {
      "text/plain": "Formatting Spike Matrix:   0%|          | 0/978 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a188de32aa6044309150c61fab4321ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Data.Encoding.Cascade.ProcessedInferences.spike_matrix = generateSpikeMatrix(Data.Encoding.Cascade.spike_time_estimates, Data.Encoding.Cascade.spike_prob.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Organize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instanced Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "# This just a dummy Log Reg to access function because im stupid rn\n",
    "Data.Encoding.LogReg = LogisticRegression(NeuralData=Data.Encoding.Cascade.ProcessedInferences.spike_matrix, FeatureDataFile=__features_file)\n",
    "\n",
    "#Organize spikes into trials x neurons x frames\n",
    "Data.Encoding.organized_spikes, Data.Encoding.feature_index, Data.Encoding.organized_features = reorganizeData(Data.Encoding.Cascade.ProcessedInferences.spike_matrix, Data.Encoding.LogReg.feature_data, Data.Encoding.Cascade.frame_rate)\n",
    "\n",
    "#Import valence data\n",
    "__csIndexFile = \"H:\\\\DEM_Excitatory_Study\\\\DEM2\\\\Encoding\\\\Behavior\\\\BehavioralExports\\\\DEM2_ENC_CS_INDEX.csv\"\n",
    "plus_trials, minus_trials = identifyTrialValence(__csIndexFile)\n",
    "plus_trials = plus_trials[0]\n",
    "minus_trials = minus_trials[0]\n",
    "\n",
    "# Segregate organized spikes by valence\n",
    "Data.Encoding.plus_spikes = Data.Encoding.organized_spikes[plus_trials, :, :]\n",
    "Data.Encoding.minus_spikes = Data.Encoding.organized_spikes[minus_trials, :, :]\n",
    "Data.Encoding.plus_features = Data.Encoding.organized_features[plus_trials, :, :]\n",
    "Data.Encoding.minus_features = Data.Encoding.organized_features[minus_trials, :, :]\n",
    "\n",
    "# Use 'Learned' Trials only\n",
    "Data.Encoding.learned_plus_spikes = Data.Encoding.plus_spikes[5:11, :, :]\n",
    "Data.Encoding.learned_minus_spikes = Data.Encoding.minus_spikes[5:11, :, :]\n",
    "Data.Encoding.learned_plus_features = Data.Encoding.plus_features[5:11, :, :]\n",
    "Data.Encoding.learned_minus_features = Data.Encoding.minus_features[5:11, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Shuffle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "_num_learned_trials = 5\n",
    "_shuf_index = np.arange(5)\n",
    "np.random.shuffle(_shuf_index)\n",
    "Data.Encoding.shuffled_learned_plus_spikes = Data.Encoding.learned_plus_spikes[_shuf_index, :, :]\n",
    "Data.Encoding.shuffled_learned_minus_spikes = Data.Encoding.learned_minus_spikes[_shuf_index, :, :]\n",
    "Data.Encoding.shuffled_learned_plus_features = Data.Encoding.learned_plus_features[_shuf_index, :, :]\n",
    "Data.Encoding.shuffled_learned_minus_features = Data.Encoding.learned_minus_features[_shuf_index, :, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use Trial Frames Only"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "Data.Encoding.new_plus = np.concatenate(Data.Encoding.shuffled_learned_plus_spikes[:, :, 492:886], axis=1)\n",
    "Data.Encoding.new_minus = np.concatenate(Data.Encoding.shuffled_learned_minus_spikes[:, :, 492:886], axis=1)\n",
    "Data.Encoding.new_plus_features = np.concatenate(Data.Encoding.shuffled_learned_plus_features[:, :, 492:886], axis=1)\n",
    "Data.Encoding.new_minus_features = np.concatenate(Data.Encoding.shuffled_learned_minus_features[:, :, 492:886], axis=1)\n",
    "Data.Encoding.new_neural_data = np.append(Data.Encoding.new_plus, Data.Encoding.new_minus, axis=1)\n",
    "Data.Encoding.new_features_data = np.append(Data.Encoding.new_plus_features, Data.Encoding.new_minus_features, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Shuffle Frames"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "_shuf_frames = np.arange(Data.Encoding.new_neural_data.shape[1])\n",
    "np.random.shuffle(_shuf_frames)\n",
    "Data.Encoding.shuffled_new_neural_data = Data.Encoding.new_neural_data[:, _shuf_frames]\n",
    "Data.Encoding.shuffled_new_features_data = Data.Encoding.new_features_data[:, _shuf_frames]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conduct Logistic Classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instanced Logistic Regression\n",
      "Splitting data in training & testing sets\n",
      "Data splits are: 80.0% training vs 20.0% testing\n",
      "Fitting Logistic Regression...\n",
      "Finished\n",
      "Training Classification Accuracy is 0.9571700507614214\n",
      "Printing Assessment of Model Performance:\n",
      "('accuracy', 'training')  :  0.9571700507614214\n",
      "('accuracy', 'testing')  :  0.9073604060913706\n",
      "('precision', 'training')  :  0.9387351778656127\n",
      "('precision', 'testing')  :  0.8487394957983193\n",
      "('recall', 'training')  :  0.8203799654576857\n",
      "('recall', 'testing')  :  0.6474358974358975\n",
      "('f1', 'training')  :  0.8755760368663594\n",
      "('f1', 'testing')  :  0.7345454545454546\n",
      "('balanced_accuracy', 'training')  :  0.9041658863433006\n",
      "('balanced_accuracy', 'testing')  :  0.8094774423888348\n",
      "('AUC', 'training')  :  0.9041658863433008\n",
      "('AUC', 'testing')  :  0.8094774423888348\n",
      "('AUC_PR', 'training')  :  0.8031144566491738\n",
      "('AUC_PR', 'testing')  :  0.6193013714661968\n"
     ]
    }
   ],
   "source": [
    "Data.Encoding.LogReg = LogisticRegression(NeuralData=Data.Encoding.shuffled_new_neural_data, FeatureData=Data.Encoding.shuffled_new_features_data)\n",
    "Data.Encoding.LogReg.label_data = Data.Encoding.LogReg.feature_data[1, :].copy()\n",
    "Data.Encoding.LogReg.splitData()\n",
    "Data.Encoding.LogReg.fitModel(penalty='l2', solver='lbfgs', max_iter=100000)\n",
    "Data.Encoding.LogReg.assessFit()\n",
    "Data.Encoding.LogReg.makeAllPredictions()\n",
    "Data.Encoding.LogReg.commonAssessment()\n",
    "Data.Encoding.LogReg.printAssessment()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "Data.Encoding.LogReg.plotROCs()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}